{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def initialize_db(db_name=\"context_data.db\"):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create a table to store contexts\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS contexts\n",
    "                     (id INTEGER PRIMARY KEY, context TEXT)''')\n",
    "    conn.commit()\n",
    "    return conn, cursor\n",
    "\n",
    "def insert_context(conn, cursor, context):\n",
    "    cursor.execute(\"INSERT INTO contexts (context) VALUES (?)\", (context,))\n",
    "    conn.commit()\n",
    "\n",
    "conn, cursor = initialize_db()\n",
    "\n",
    "# Insert a sample context\n",
    "# insert_context(conn, cursor, \"The sun is a star located at the center of our Solar System.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (2.0.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Downloading model.safetensors: 100%|██████████| 1.52G/1.52G [03:40<00:00, 6.88MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 42.8kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./local_gpt2_model/tokenizer_config.json',\n",
       " './local_gpt2_model/special_tokens_map.json',\n",
       " './local_gpt2_model/vocab.json',\n",
       " './local_gpt2_model/merges.txt',\n",
       " './local_gpt2_model/added_tokens.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your saving path\n",
    "save_directory = \"./local_gpt2_model\"\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Local Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall your saving path\n",
    "save_directory = \"./local_gpt2_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the model\n",
    "model = GPT2LMHeadModel.from_pretrained(save_directory)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_gpt2(question, context, max_length=500):\n",
    "    input_text = f\"{context}. {question}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    \n",
    "    # Generate a response from the model\n",
    "    outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "    \n",
    "    # Decode the output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # The answer is whatever was added by the model, after the input text\n",
    "    answer = generated_text[len(input_text):].strip()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_contexts(cursor):\n",
    "    cursor.execute(\"SELECT context FROM contexts\")\n",
    "    return [row[0] for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_contexts(question, cursor, limit=5):\n",
    "    # Extract keywords from the question (this is a simple approach, can be improved)\n",
    "    keywords = question.split()\n",
    "    \n",
    "    # Query the database to find contexts that contain the keywords\n",
    "    contexts = []\n",
    "    for keyword in keywords:\n",
    "        cursor.execute(\"SELECT context FROM contexts WHERE context LIKE ?\", ('%' + keyword + '%',))\n",
    "        contexts.extend([row[0] for row in cursor.fetchall()])\n",
    "        \n",
    "    # Return unique contexts and limit the number of results\n",
    "    return list(set(contexts))[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate with the retriever\n",
    "def answer_question_gpt2(question, cursor):\n",
    "    contexts = retrieve_all_contexts(cursor)\n",
    "    for context in contexts:\n",
    "        answer = generate_answer_gpt2(question, context)\n",
    "        if answer:\n",
    "            return answer\n",
    "    return \"I don't have enough information to answer that question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_gpt2_v2(question, cursor):\n",
    "    # Fetch the most relevant contexts for the question\n",
    "    contexts = retrieve_relevant_contexts(question, cursor)\n",
    "    \n",
    "    # If no context found, provide a default answer\n",
    "    if not contexts:\n",
    "        return \"I don't have enough information to answer that question.\"\n",
    "    \n",
    "    # Loop through each context and generate an answer using GPT-2\n",
    "    for context in contexts:\n",
    "        answer = generate_answer_gpt2(question, context)\n",
    "        if answer:\n",
    "            return answer\n",
    "    return \"I couldn't generate a satisfactory answer based on the provided contexts.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the stars? How do you know the weather? Where are you? Who are your neighbors? Do you have a car? Are you a student? A teacher? An employee? Is your car insured? If you are a resident of the City of Chicago, you may submit a bid for a vehicle. If your bid is accepted, the vehicle will be placed on the auction block. The bidding will begin at the beginning of bidding and will continue until all bids have been received. When the bidding is complete, a winner will receive a receipt for the winning bid. A winner may not be required to pay any additional fees or taxes.\n",
      "\n",
      "Bidding on a Vehicle: When a bidder places a winning bidder, he or she will have the right to bid on behalf of any other bidder. Bidding will not take place until the closing of bids. In the event that a bidding war occurs, each bidder will bid in the order in which they placed their bids, and the winner of that bidding conflict will win the bid that was placed first. No bid will exceed the highest bid received by the lowest bidder in that bid war. All bids will go to the person who placed the most bids in all of those bids and who is then the sole winner. Any bid placed after the close of all bidding wars will result in a loss to that bidder and may result the bidder to be disqualified from bidding on any future auctions.\n",
      "\n",
      "\n",
      "The following is a list of items that may be offered for sale on this auction:\n",
      ",\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Sample question\n",
    "print(answer_question_gpt2_v2(\"What is the sun?\", cursor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding DPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split_data(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        # Read all lines from the file\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Join lines and split by '.'\n",
    "        full_text = ''.join(lines)\n",
    "        contexts = full_text.split('.')\n",
    "        \n",
    "        # Strip whitespaces from each context\n",
    "        return [context.strip() for context in contexts if context.strip()]\n",
    "    \n",
    "# Step 1: Initialize the database\n",
    "conn, cursor = initialize_db()\n",
    "\n",
    "# Step 2: Read and split the data from the file\n",
    "contexts = read_and_split_data('content_Defence_Audit_Manual_Vol_A_Office_Mannual_20210121123223.txt')\n",
    "\n",
    "# Step 3: Insert each context into the database\n",
    "for context in contexts:\n",
    "    insert_context(conn, cursor, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "1. To ensure that the financial management of a department is in accordance with the law and the regulations.\n",
      "2. In the event of any irregularities, to ensure the proper management and control of funds. 3. If the audit is not carried out in a timely manner, or if the report is incomplete, the\n",
      "departmental head should be informed of such irregulars and should take appropriate measures to rectify them. The DGAD has\n",
      "also recommended that a report on the performance of audit functions should also be prepared by\n",
      "the DGAS.\n"
     ]
    }
   ],
   "source": [
    "# Sample question on DPM\n",
    "print(answer_question_gpt2_v2(\"What are the top 3 general duties of command officers and senior audit officers\", cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vauche is the Latin word for \"to make a bargain\" and is used to describe a legal agreement. It is also used in the English language to mean a written contract or a document that is signed by two or more parties.\n",
      ",\n",
      ".\n",
      "\n",
      ",\n",
      "\n",
      " ,  . \n",
      "  \n",
      " vauch is not a word that means \"a contract\" or \"an agreement\". It means a set or series of agreements, or the agreement of two parties to a common object. The word vaul is derived from the French word \"vauler\" which means to make an offer or contract.\n",
      "Vaucher is one of the most common terms used for legal agreements. A vauncher agreement is usually a formal agreement between two people who have agreed to the terms of a particular contract and to pay a certain amount of money. In the United States, vouchers are usually written in a form that makes it easy for the parties involved to understand and agree to it. Voucher agreements are often used as a way to settle disputes between parties, to resolve disputes over the amount or terms that should be paid, and as an alternative to legal action. vouching is another common term used by vuchers. This is when a person or group of people makes a vouched agreement to give money to another person, group or organization. For example, in order to vaunt a group to help pay for an emergency, the vaunted group would vout a pledge to do so. If the pledge is broken, then the group is liable for any damages that may result from that breach.\n"
     ]
    }
   ],
   "source": [
    "# Sample question on DPM\n",
    "print(answer_question_gpt2_v2(\"What is Vsauce?\", cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science is the study of the natural world, the understanding of its laws, and the application of those laws to human affairs. Science is also the art of understanding the laws of nature, of applying those principles to the human condition.\n",
      ",\n",
      "...\n",
      "\n",
      "\n",
      " \n",
      "The first part of this book is devoted to a discussion of what is science, what it is not, how it differs from other sciences, its relation to religion, philosophy, politics, economics, law, art, literature, etc. The second part is concerned with the nature of science and its relationship to other branches of knowledge. It is then followed by a brief discussion on the relationship between science as a science of human knowledge and science in general.\n",
      "\n",
      ",\n",
      "\n",
      "  .  \n",
      "A. A. Smith, The Science of Human Knowledge, (New York: Harper & Brothers, 1894), p. 5. B. J. F. Huxley, Science and Society, p, 5-6. C. W. M. G. S. Lewis, \"The Nature of Science,\" in The Cambridge History of Philosophy, ed. R. L. Macpherson (Cambridge: Cambridge University Press, 1960), pp. 4-5. D. P. Leibniz, Principles of Geometry, vol. 1, pp, 437-441. E. T. Wilson, A Treatise on Geography, Vol. 2, Lectures on Natural History, London, 1776, 2 vols. (London: Printed for the Royal Society of London by the author, 1688), vol 1. pp., 447-450. f. O. Schleiermacher, Geometrical Geology, 3rd ed., (Boston: Houghton Mifflin, 1900), Vols 1-2. g. K. N. Stokes, Natural Geographical Geographies, 1st ed, New York, 1899, 6 vol, Cambridge, Mass.: Harvard University, 1902, 7 vol (2nd ed.). h. V. Z. Shanks, History and Geopolitics of India\n"
     ]
    }
   ],
   "source": [
    "print(answer_question_gpt2_v2(\"What is Science?\", cursor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
