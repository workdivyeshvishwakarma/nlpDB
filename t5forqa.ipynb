{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "def initialize_db(db_name=\"context_DPM_data.db\"):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create a table to store contexts\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS contexts\n",
    "                     (id INTEGER PRIMARY KEY, context TEXT)''')\n",
    "    conn.commit()\n",
    "    return conn, cursor\n",
    "\n",
    "# Connect to DB\n",
    "conn, cursor = initialize_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 1.02MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 2.32k/2.32k [00:00<00:00, 486kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_and_confidence(context, question):\n",
    "    # Format the question and context for T5\n",
    "    input_text = f\"question: {question} context: {context}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Get the output tokens from the model using the generate method\n",
    "    outputs = model.generate(inputs[\"input_ids\"], num_return_sequences=1)\n",
    "\n",
    "    # Convert the generated token IDs to a string\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Get logits for the generated tokens\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs[\"input_ids\"], decoder_input_ids=outputs).logits\n",
    "\n",
    "    # Compute the probabilities from the logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    real_probs = torch.gather(probs, 2, outputs.unsqueeze(-1))\n",
    "    confidence = real_probs.log().mean().exp().item()\n",
    "\n",
    "    return answer, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def rank_contexts_by_relevance(question, contexts, top_n=5):\n",
    "    # Vectorize the question and contexts using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer().fit_transform([question] + contexts)\n",
    "    \n",
    "    # Compute the cosine similarity between the question and each context\n",
    "    cosine_similarities = cosine_similarity(tfidf_vectorizer[0:1], tfidf_vectorizer).flatten()\n",
    "    \n",
    "    # Get the indices of the top_n most similar contexts\n",
    "    relevant_indices = cosine_similarities.argsort()[:-top_n-1:-1]\n",
    "    \n",
    "    # Select the most relevant contexts based on the indices\n",
    "    most_relevant_contexts = [contexts[i-1] for i in relevant_indices][1:]  # We exclude the first item since it's the question itself\n",
    "\n",
    "    return list(set(most_relevant_contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexts_for_filter_keywords(conn, cursor, question, filter_keywords):\n",
    "    \n",
    "    # Construct the query to search for contexts containing keywords\n",
    "    query_clauses = [\"context LIKE ?\" for _ in filter_keywords]\n",
    "    query = \"SELECT context FROM contexts WHERE \" + \" OR \".join(query_clauses)\n",
    "    params = ['%' + keyword + '%' for keyword in filter_keywords]\n",
    "    \n",
    "    cursor.execute(query, params)\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    # Extract contexts from the results\n",
    "    contexts = [result[0] for result in results]\n",
    "    relevant_contexts = rank_contexts_by_relevance(question, contexts)\n",
    "    \n",
    "    return relevant_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ILMSI/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def filter_keywords(question):\n",
    "    keywords = question.split()\n",
    "    filtered_keywords = [word for word in keywords if word.lower() not in stop_words and len(word) > 2]  # We also filter out words with length <= 2\n",
    "    return filtered_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is termed as Liquidated Damages?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Force Majeure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Deadline for Submission of Quotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/generation/utils.py:1357: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Place and deadline for receipt of tenders\n",
      "Answer: Place and deadline for receipt of tenders\n",
      "Confidence Score: 0.0000\n",
      "--------------------------------------------------\n",
      "Context: Modification and Withdrawal of Bids: A bidder may modify or withdraw his bid after submission provided that the written notice of modification or withdrawal is received by the Buyer prior to deadline prescribed for submission of bids. A withdrawal notice may be sent by fax but it should be followed by a signed confirmation copy to be sent by post and such signed confirmation should reach the purchaser not later than the deadline for submission of bids. No bid shall be modified after the deadline for submission of bids. No bid may be withdrawn in the interval between the deadline for submission of bids and expiration of the period of bid validity specified. Withdrawal of a bid during this period will result in Bidder’s forfeiture of bid security.\n",
      "Answer: No bid shall be modified after the deadline for submission of bids\n",
      "Confidence Score: 0.0000\n",
      "--------------------------------------------------\n",
      "##################################################\n",
      "The best answer is:  Place and deadline for receipt of tenders\n"
     ]
    }
   ],
   "source": [
    "# All Answer with Confidence score printer\n",
    "def get_answers_for_all_contexts(question):\n",
    "    # Get contexts related to the question from your database\n",
    "    filtered_keywords = filter_keywords(question)\n",
    "    contexts = get_contexts_for_filter_keywords(conn, cursor, question, filtered_keywords)\n",
    "    best_confidence = -1\n",
    "    best_answer = \"\"\n",
    "    # Go through each context and generate answers\n",
    "    for context in contexts:\n",
    "        answer, confidence = get_answer_and_confidence(context, question)\n",
    "        if confidence > best_confidence:\n",
    "            best_confidence = confidence\n",
    "            best_answer = answer\n",
    "        print(f\"Context: {context}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(f\"Confidence Score: {confidence:.4f}\")\n",
    "        print(\"-\" * 50)  # separator line for better readability\n",
    "    print(\"#\"*50)\n",
    "    print(\"The best answer is: \", best_answer)\n",
    "\n",
    "get_answers_for_all_contexts(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
